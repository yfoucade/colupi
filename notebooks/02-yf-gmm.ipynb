{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "import sklearn.cluster\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numba import njit\n",
    "from copy import deepcopy\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collaborator:\n",
    "    \"\"\"\n",
    "    An abstract class representing a collaborator.\n",
    "    Collaborators can be of different types (running with different algorithms)\n",
    "    e.g. Gtms, gaussian mixture models, other mixture models, or any kind of probabilistic model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, Y=None, K=3, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        Id: np.array(int)\n",
    "            N-dimensional array, Id of each individual.\n",
    "        X: np.ndarray(float)\n",
    "            N*D array of features.\n",
    "        Y (optional): np.array(int)\n",
    "            N-dimensional array, labels.\n",
    "        K (optional): int\n",
    "            number of clusters\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        if kwargs.get('add_noise', False):\n",
    "            \n",
    "        \n",
    "    @abstractmethod\n",
    "    def local_step(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def log_local(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def collaborate(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def log_collab(self):\n",
    "        pass\n",
    "    \n",
    "    def get_partition_matrix(self):\n",
    "        return self.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gmm:\n",
    "    \"\"\"\n",
    "    A class for Gaussian mixture models.\n",
    "\n",
    "    Attributes:\n",
    "        K (int): number of components.\n",
    "        tol (float): convergence threshold. EM stops when variation of the\n",
    "            parameters between two steps is below this threshold.\n",
    "        n_iter (int): number of iterations to convergence.\n",
    "        X (np.array): n*D array of data.\n",
    "        \n",
    "        n (int): number of observations.\n",
    "        D (int): dimensionality of one data point.\n",
    "        prop (np.array): 1*K array with the probabilities of each component.\n",
    "        mu    (np.array): K*D array: the K means of the densities.\n",
    "        sigma (np.array): K*D*D array: K covariance matrices of densities.\n",
    "        tau   (np.array): n*K responsability matrix.\n",
    "        pairwise_entropy (np.array): n*n array of pairwise cross-entropy.\n",
    "        average_entropy (np.array): = (1/n) * trace(pairwise_entropy).\n",
    "        uncertainty (np.array): 1 minus the highest responsability,\n",
    "            for each observation.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    @njit\n",
    "    def __init__(self, K=3, tol=1e-2, max_iter=0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            K (int): Number of clusters\n",
    "            tol (float): when to stop the algorithm\n",
    "        \"\"\"\n",
    "        \n",
    "        self.K, self.tol, self.max_iter = K, tol, max_iter\n",
    "\n",
    "        # number of iterations\n",
    "        self.n_iter = None\n",
    "\n",
    "        # the design matrix and its shape\n",
    "        self.X, self.n, self.D = None, None, None\n",
    "\n",
    "        # parameters of the model\n",
    "        self.prop, self.mu, self.sigma, self.tau = 4*[None]\n",
    "\n",
    "        # some information-theoretic variables\n",
    "        self.pairwise_entropy, self.average_entropy, self.uncertainty = 3*[None]\n",
    "       \n",
    "    \n",
    "    @njit\n",
    "    def fit(X, resp=None):\n",
    "        \"\"\"\n",
    "        Infers on the data X\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): 2-dimensional array of shape n*D (number of observations * number of variables).\n",
    "            resp (np.ndarray): 2-dimensional array of shape n*K: responsibility matrix.\n",
    "\n",
    "        Returns:\n",
    "            sets the following attributes:\n",
    "            prop  (np.ndarray): K-dimensional vector, the proportions of the mixture model.\n",
    "            mu    (np.ndarray): K*D array: the K means of the densities.\n",
    "            sigma (np.ndarray): K*D*D array: K covariance matrices of densities.\n",
    "            tau   (np.ndarray): n*K responsability matrix.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X.copy()\n",
    "\n",
    "        # if X is a line vector, transform it to a column vector (we need a 2D array)\n",
    "        if self.X.ndim == 1:\n",
    "            self.X = self.X.reshape(-1, 1)\n",
    "\n",
    "        self.n, self.D = self.X.shape\n",
    "\n",
    "        # initialization\n",
    "        if resp is None:\n",
    "            new_tau = self.warm_start(self.X, self.K)\n",
    "        else:\n",
    "            # one could add ```assert is_partition_matrix(resp)```\n",
    "            new_tau = resp.copy()\n",
    "        new_prop, new_mu, new_sigma = self.m_step(X, new_tau)\n",
    "\n",
    "        delta, self.n_iter = 1, 0\n",
    "\n",
    "        while True:\n",
    "            self.n_iter += 1\n",
    "            #print(\"iter number {}\".format(self.n_iter))\n",
    "            # save old values\n",
    "            old_prop, old_mu, old_sigma, old_tau = deepcopy(new_prop), deepcopy(new_mu), deepcopy(new_sigma), deepcopy(new_tau)\n",
    "\n",
    "            # compute new values: e-step followed by m-step\n",
    "            new_tau = self.e_step(X, old_prop, old_mu, old_sigma)\n",
    "            new_prop, new_mu, new_sigma = self.m_step(X, new_tau)\n",
    "\n",
    "            # compute variation of the parameters\n",
    "            if self.n_iter > 2:\n",
    "                delta = np.linalg.norm(new_mu - old_mu) + np.linalg.norm(new_sigma - old_sigma)\n",
    "                \n",
    "            if delta <= self.tol or (self.max_iter and self.n_iter == self.max_iter):\n",
    "                break\n",
    "\n",
    "        self.prop, self.mu, self.sigma, self.tau = new_prop.copy(), new_mu.copy(), new_sigma.copy(), new_tau.copy()\n",
    "\n",
    "        return self.prop, self.mu, self.sigma, self.tau\n",
    "    \n",
    "    \n",
    "    @njit\n",
    "    @staticmethod\n",
    "    def get_density(value, mean=None, cov=None):\n",
    "        try:\n",
    "            return scipy.stats.multivariate_normal.pdf(value, mean=mean, cov=cov, allow_singular=True)\n",
    "        except:\n",
    "            print(\"Trying to get density for value {}, mean {}, and cov {}\".format(value, mean, cov))\n",
    "\n",
    "    \n",
    "    @njit\n",
    "    @staticmethod\n",
    "    def warm_start(X, K=3, epsilon=1e-3):\n",
    "        \"\"\"\n",
    "        Initializes the parameters prop, mu, and sigma using sklearn.cluster.k_means()\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): 2-dimensional array of shape n*D (number of observations * number of variables)\n",
    "            K (int): Number of clusters.\n",
    "            epsilon (float): small pertubation to cluster assignements (avoids clusters with one object).\n",
    "\n",
    "        Return:\n",
    "            resp (np.ndarray): responsibility matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        centroids, pred_labels, inertia, n_iter = sklearn.cluster.k_means(X, K, return_n_iter=True)\n",
    "\n",
    "        resp = pd.get_dummies(pred_labels).values + epsilon\n",
    "        resp /= 1 + K*epsilon\n",
    "\n",
    "        return resp\n",
    "\n",
    "    \n",
    "    @njit\n",
    "    def e_step(self, X, prop, means, covs, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Proceeds to the e-step of the EM algorithm.\n",
    "\n",
    "        Args:\n",
    "            X     (np.ndarray): 2-dimensional array of shape n*D (number of observations * number of variables)\n",
    "            prop  (np.ndarray): K-dimensional vector, the proportions of the mixture model.\n",
    "            means (np.ndarray): K*D array: the K means of the densities.\n",
    "            covs  (np.ndarray): K*D*D array: K covariance matrices of densities.\n",
    "\n",
    "        Returns:\n",
    "            resp  (np.ndarray): n*K responsability matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        n, D = X.shape\n",
    "        K = means.shape[0]\n",
    "\n",
    "        resp = np.zeros((n, K))\n",
    "        for i in range(n):\n",
    "            for k in range(K):\n",
    "                resp[i, k] += prop[k] * self.get_density(X[i], means[k], covs[k])\n",
    "        resp += epsilon\n",
    "        resp /= 1+K*epsilon\n",
    "        resp /= resp.sum(axis=1, keepdims=True)\n",
    "        return resp\n",
    "\n",
    "    \n",
    "    @njit\n",
    "    @staticmethod\n",
    "    def m_step(X, resp):\n",
    "        \"\"\"\n",
    "        Proceeds to the e-step of the EM algorithm.\n",
    "\n",
    "        Args:\n",
    "            X     (np.ndarray): 2-dimensional array of shape n*D (number of observations * number of variables)\n",
    "            resp  (np.ndarray): n*K responsability matrix.\n",
    "\n",
    "        Returns:\n",
    "            new_prop  (np.ndarray): K-dimensional vector, the proportions of the mixture model.\n",
    "            new_means (np.ndarray): K*D array: the K means of the densities.\n",
    "            new_covs  (np.ndarray): K*D*D array: K covariance matrices of densities.\n",
    "        \"\"\"\n",
    "\n",
    "        n, D = X.shape\n",
    "        K = resp.shape[1]\n",
    "        nk = resp.sum(axis=0, keepdims=False)\n",
    "\n",
    "        # new_prop\n",
    "        new_prop = resp.sum(axis=0) / n\n",
    "        #print(\"new_prop: {}\".format(new_prop))\n",
    "\n",
    "        # new_means\n",
    "        new_means = resp.T.dot(X) / resp.T.sum(axis=1, keepdims=True)\n",
    "        #print(\"new_means: {}\".format(new_means))\n",
    "\n",
    "        # new_covs\n",
    "        new_covs = np.zeros((K, D, D))\n",
    "        for k in range(K):\n",
    "            diff = X - new_means[k]\n",
    "            new_covs[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        #print(\"new_covs: {}\".format(new_covs))\n",
    "\n",
    "        return new_prop, new_means, new_covs\n",
    "\n",
    "    \n",
    "    @njit\n",
    "    def get_params(self):\n",
    "        return self.prop, self.mu, self.sigma, self.tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collaborator_gmm(Collaborator):\n",
    "    \"\"\"\n",
    "    A Gaussian mixture model based collaborator\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    @njit\n",
    "    def __init__(self, Id, X, Y=None, K=3, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        Id: np.array(int)\n",
    "            N-dimensional array, Id of each individual.\n",
    "        X: np.ndarray(float)\n",
    "            N*D array of features.\n",
    "        Y (optional): np.array(int)\n",
    "            N-dimensional array, labels.\n",
    "        K (optional): int\n",
    "            number of clusters\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(X=X, Y=Y, K=K)\n",
    "        \n",
    "        \n",
    "    @njit\n",
    "    def local_step(self):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijcnn21",
   "language": "python",
   "name": "ijcnn21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
