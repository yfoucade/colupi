{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from abc import abstractmethod\n",
    "\n",
    "from numba import njit\n",
    "from numba import int32, float32    # import the types\n",
    "from numba.experimental import jitclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Master(object):\n",
    "    \"\"\"\n",
    "    Master algorithm managing the collaboration between the local data sites\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, collabs=None, max_iter=0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        collabs: list(Collaborator)\n",
    "            List of instances of type \"Collaborator\".\n",
    "        max_iter (optional): int\n",
    "            Maximum number of iterations in the collaborative phase\n",
    "            \n",
    "        optional:\n",
    "        X (optional): list(pandas.DataFrame)\n",
    "            List of dataframes with same size than collabs.\n",
    "            The view of each collaborators, with acces to possibly different\n",
    "            set of individuals (identified by the index column).\n",
    "        Y (optional): list(pandas.DataFrame)\n",
    "            List of dataframes, one for each collaborator. With the indices and the labels.\n",
    "            \n",
    "        notes:\n",
    "        02/02 14:16 - Xs and Ys are not necessary parameters, as we can get them from each collab.\n",
    "                      Consider removing them.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.collabs, self.P = collabs, len(collabs)\n",
    "        for i, collab in enumerate(self.collabs):\n",
    "            collab.set_id(i)\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        # create a log that will contain information about each step of the process\n",
    "        self.log = [] # validation indices (for each step, a list of dicts)\n",
    "        self.collaboration_history = [] # confidence matrices\n",
    "        \n",
    "        \n",
    "    def launch_collab(self):\n",
    "        \"\"\"\n",
    "        Proceed to the collaboration.\n",
    "        \"\"\"\n",
    "        \n",
    "        # each collaborator fits its parameters in the local step\n",
    "        to_log = []\n",
    "        for collab in self.collabs:\n",
    "            collab.local_step()\n",
    "            to_log.append(deepcopy(collab.log_local()))\n",
    "        # log\n",
    "        self.log.append(deepcopy(to_log))\n",
    "        \n",
    "        n_iter=0\n",
    "        while True:\n",
    "            stop, to_log = True, []\n",
    "            \n",
    "            #save all collaboration matrices\n",
    "            \n",
    "            # each data site is in turn considered as the local data site\n",
    "            for p, collab in enumerate(collabs):\n",
    "                # it is provided with a tuple for each remote data site: (Id, partition_matrix)\n",
    "                remote_Ids, remote_partitions = self.get_partitions_except_p(p)\n",
    "                successful_collab = collab.collaborate(remote_Ids, remote_partitions)\n",
    "                to_log.append(deepcopy(collab.log_collab()))\n",
    "                if successful_collab:\n",
    "                    stop = False\n",
    "            \n",
    "            # log the results\n",
    "            self.log.append(deepcopy(to_log))\n",
    "            \n",
    "            # should we stop ?\n",
    "            if stop:\n",
    "                break\n",
    "            # if stop==False, then a collaboration occured, add 1 to counter\n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter == self.max_iter:\n",
    "                break\n",
    "            \n",
    "    \n",
    "    def get_partitions_except_p(self, p):\n",
    "        \"\"\"\n",
    "        Get all partition matrices except number p.\n",
    "        This is used to get every remote partition matrix when p is the local data site.\n",
    "        \n",
    "        Parameters:\n",
    "            p: int\n",
    "                id of the partition matrix to ignore.\n",
    "        \"\"\"\n",
    "        \n",
    "        res_Ids, res_partitions = []\n",
    "        for i, collab in self.collabs:\n",
    "            if i != p:\n",
    "                res_Ids.append(collab.get_id())\n",
    "                res_partitions.append(deepcopy(collab.get_partition_matrix()))\n",
    "        return res_Ids, res_partitions\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijcnn21",
   "language": "python",
   "name": "ijcnn21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
